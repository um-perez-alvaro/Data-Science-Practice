{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: a linguistic street map of Singapore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is considerable linguistic variety in Singapore road names: Malaysians names (Jalan Besar), British names (Northumberland road), Chinese names (Keong Saik Road), Indian names (Veerasamy road), Jewish names (Belilios road), and the usual generic sorts of names that describe either area landmarks or other common noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](streets.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tag</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saiboo</td>\n",
       "      <td>Street</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merchant</td>\n",
       "      <td>Loop</td>\n",
       "      <td>Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hill</td>\n",
       "      <td>Street</td>\n",
       "      <td>Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ophir</td>\n",
       "      <td>Road</td>\n",
       "      <td>Malay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buona</td>\n",
       "      <td>Vista Road</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sengkang</td>\n",
       "      <td>Avenue</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>Avenue</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brickland</td>\n",
       "      <td>Road</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Choa Chu Kang</td>\n",
       "      <td>Road</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Woodlands</td>\n",
       "      <td>Avenue</td>\n",
       "      <td>Generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name         tag   origin\n",
       "0         Saiboo      Street   Indian\n",
       "1       Merchant        Loop  Generic\n",
       "2           Hill      Street  Generic\n",
       "3          Ophir        Road    Malay\n",
       "4          Buona  Vista Road    Other\n",
       "5       Sengkang      Avenue  Chinese\n",
       "6     Ang Mo Kio      Avenue  Chinese\n",
       "7      Brickland        Road  British\n",
       "8  Choa Chu Kang        Road  Chinese\n",
       "9      Woodlands      Avenue  Generic"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/streets.csv'\n",
    "street_names = pd.read_csv(url)\n",
    "street_names.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``Origin`` column values:**\n",
    "\n",
    "- Chinese (all dialects including Cantonese, Hokkien, Mandarin, etc)\n",
    "- Malay\n",
    "- Indian (all languages of the subcontinent)\n",
    "- British\n",
    "- Generic (Race Course Road, Sunrise Place, etc)\n",
    "- Other (Other languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Malay      927\n",
       "British    798\n",
       "Generic    497\n",
       "Chinese    403\n",
       "Other      167\n",
       "Indian      42\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_names.origin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **goal** is to predict the ``origin`` column from the ``street`` and ``tag`` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1:** Add the following features:\n",
    "\n",
    "- Number of words in road name (more words => more likely to be Chinese.) Assign it to a column named `n_words`.\n",
    "- Average word length in road name (longer words => more likely to be British or Indian.) Assign it to a column named `avg_word_len`.\n",
    "- Is the road tag Malay? (if yes => very correlated with being Malay.) **Malay tags**: *Jalan*, *Lorong*, *Bukit*, *Lengkok*, *Taman*, *Kampong*, *Lengkong*. Assign it to a column named `is_malay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_words_name(name):\n",
    "    return len(name.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_names['n_words'] = street_names.name.apply(n_words_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(name):\n",
    "    words = name.split(' ')\n",
    "    n_words = len(words)\n",
    "    lengths = np.array([len(word) for word in words])\n",
    "    return np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_names['avg_len'] = street_names.name.apply(avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_malay(tag):\n",
    "    return tag in  ['Jalan', 'Lorong', 'Bukit', 'Lengkok', 'Taman', 'Kampong', 'Lengkong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_names['is_malay'] = street_names.tag.apply(is_malay).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tag</th>\n",
       "      <th>origin</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_len</th>\n",
       "      <th>is_malay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saiboo</td>\n",
       "      <td>Street</td>\n",
       "      <td>Indian</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merchant</td>\n",
       "      <td>Loop</td>\n",
       "      <td>Generic</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hill</td>\n",
       "      <td>Street</td>\n",
       "      <td>Generic</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ophir</td>\n",
       "      <td>Road</td>\n",
       "      <td>Malay</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buona</td>\n",
       "      <td>Vista Road</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>Florence</td>\n",
       "      <td>Close</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>Hoot Kiam</td>\n",
       "      <td>Road</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>Clarke</td>\n",
       "      <td>Quay</td>\n",
       "      <td>British</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>Countryside</td>\n",
       "      <td>Walk</td>\n",
       "      <td>Generic</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>Park</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name         tag   origin  n_words  avg_len  is_malay\n",
       "0          Saiboo      Street   Indian        1      6.0         0\n",
       "1        Merchant        Loop  Generic        1      8.0         0\n",
       "2            Hill      Street  Generic        1      4.0         0\n",
       "3           Ophir        Road    Malay        1      5.0         0\n",
       "4           Buona  Vista Road    Other        1      5.0         0\n",
       "...           ...         ...      ...      ...      ...       ...\n",
       "2829     Florence       Close  Chinese        1      8.0         0\n",
       "2830    Hoot Kiam        Road  Chinese        2      4.0         0\n",
       "2831       Clarke        Quay  British        1      6.0         0\n",
       "2832  Countryside        Walk  Generic        1     11.0         0\n",
       "2833        Nepal        Park    Other        1      5.0         0\n",
       "\n",
       "[2834 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2:** define the matrix X (columns `name`, `n_words`, `avg_word_len`, `is_malay`) and the target vector y (column `origin`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = street_names.drop(['tag','origin'],axis=1)\n",
    "y = street_names.origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3:** split X and y into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4:** build a classification pipeline.\n",
    "\n",
    "The pipeline must use `CountVectorizer` to compute the number of **character 1-gram, 2-grams, 3-grams and 4-grams** from the column `name` ([CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) has an `analyzer` parameter that you'll have to set to `analyzer='char'`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('name_processor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('vect',\n",
       "                                                  CountVectorizer(analyzer='char',\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               4)),\n",
       "                                                  'name')])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_processor = ColumnTransformer(transformers=[\n",
    "    ('vect',CountVectorizer(analyzer='char',ngram_range=(1,4)),'name')\n",
    "],remainder='passthrough')\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('name_processor',name_processor),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 5:** Fit the classification pipeline to the training data, and  evaluate its performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('name_processor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('vect',\n",
       "                                                  CountVectorizer(analyzer='char',\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               4)),\n",
       "                                                  'name')])),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[796,   0,   1,   0,   1,   0],\n",
       "       [  0, 403,   0,   0,   0,   0],\n",
       "       [  0,   0, 497,   0,   0,   0],\n",
       "       [  0,   0,   0,  41,   1,   0],\n",
       "       [  0,   0,   0,   0, 927,   0],\n",
       "       [  0,   0,   0,   0,   2, 165]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982357092448836"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
