{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69300c-fbfa-4abe-bd0f-dba147a773e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97875275-195f-436f-88aa-05d01a992920",
   "metadata": {},
   "source": [
    "# Tuning the decision threshold for class prediction and imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1343276-1ba7-42b8-b07c-db50cbb4abea",
   "metadata": {},
   "source": [
    "An imbalanced dataset has one class with many more examples than the other. This makes it tricky because models tend to focus on the majority class and may ignore the minority class, which is often the more important one, like fraud detection or diagnosing rare diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777aea3-993e-4b45-807b-1caf941655f6",
   "metadata": {},
   "source": [
    "Let's look at an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172d1e1-9ee8-40ec-83e0-a7ad63509e80",
   "metadata": {},
   "source": [
    "## 1. The Adult Census Income Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15630b4-0c84-4aaf-9f2c-c954dd090f52",
   "metadata": {},
   "source": [
    "For our example, we'll use the Adult Census Income dataset. This dataset contains information about people's age, education, work, and more. The goal is to predict whether a person earns more than $50,000 a year based on their demographic and work-related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68512bb-58cc-49d9-a4bc-b88fe9ea09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/adult_census.csv'\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a9ddf-aefa-458c-b605-75ecd710872a",
   "metadata": {},
   "source": [
    "To check if the dataset is imbalanced, we can look at the distribution of the target variable (whether someone earns more than $50K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05c49b-c9d9-413f-971a-40a5aa14e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c710542-d1b8-4cb2-9965-acb9d62694a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ec37b-8b12-415d-a764-b9247ab5d62c",
   "metadata": {},
   "source": [
    "The results show that 37,155 people earn <=50K (97%), while only 1,169 earn >50K (3%). This large difference confirms that the dataset is heavily imbalanced, with far more people in the <=50K class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132a35f-a1ab-40a4-9eca-b8678869d73b",
   "metadata": {},
   "source": [
    "## 2. When Accuracy Misleads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69046da-f056-49ce-8cb1-7d76848bcad0",
   "metadata": {},
   "source": [
    "Let's put together a simple classification pipeline. Nothing fancy. We'll impute missing values, scale the numerical features, and one-hot encode the categorical features. After that, we'll add my favorite model: [the dummy classifier](https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9469cb-c5f8-4d27-b6dc-acce95531ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07da48-945e-4f0b-8387-6ca5aebfa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['age','fnlwgt','education-num','capitalgain','capitalloss','hoursperweek']\n",
    "cat_features = ['workclass','marital-status','occupation','relationship','race','sex','native-country']\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',MinMaxScaler())\n",
    "])\n",
    "\n",
    "feature_processor = ColumnTransformer(transformers=[\n",
    "    ('num',num_pipeline,num_features),\n",
    "    ('cat',cat_pipeline,cat_features)\n",
    "])\n",
    "\n",
    "pipe_dummy_clf = Pipeline(steps=[\n",
    "    ('processor', feature_processor),\n",
    "    ('clf',DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "pipe_dummy_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dfaf3-da21-4781-926f-770a366964e4",
   "metadata": {},
   "source": [
    "The dummy classifier is, as the name suggests, 'dummy.' It always predicts the majority class, which in our case is `<=50K`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e713b80-e833-477e-a54a-1b1635b28165",
   "metadata": {},
   "source": [
    "Let's now evaluate our amazing model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ad8b8-70ac-475e-8b7f-8ac5d2defde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix X, target vector y\n",
    "X = df.drop(['education', 'label'], axis=1) # Dropping 'education' because 'num-education' has the same info\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42e633-e9cb-41ca-9260-041743de092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5b19b-32a6-4eca-9dd9-166da1fd7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dummy_clf.fit(X_train,y_train)\n",
    "y_test_pred = pipe_dummy_clf.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e22e46-b09d-4142-a0cc-f6d6b86703ef",
   "metadata": {},
   "source": [
    "Let's check the accuracy of our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a23b8c-7fda-4830-b021-c9ea6a43368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736131d-6406-4d6d-9d7f-b5135d963f6f",
   "metadata": {},
   "source": [
    "Wow! 97% of the predictions are correct.\n",
    "Not too bad, right? \n",
    "But hold on a second. \n",
    "There's a big problem here.\n",
    "Our dataset is very imbalanced.\n",
    "The model is just predicting the majority class (`<=50K`) all the time. \n",
    "That’s why the accuracy looks good, but it’s not actually telling us how well the model is doing with the minority class (`>50K`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c8092-ce5d-483f-a252-e4de430b8508",
   "metadata": {},
   "source": [
    "So be careful when using evaluation metrics like accuracy on an imbalanced dataset. Your model might not be as good as it seems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef26ffa-2184-4cd1-afab-f81fdb3852a5",
   "metadata": {},
   "source": [
    "## 2. A Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60da6f-33b2-47a7-b8d8-d2df0dfbcda4",
   "metadata": {},
   "source": [
    "Back to more serious business. Let's replace the dummy classifier with a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48eadf-287b-46ed-b69b-4c2c03fc3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipe_tree_clf = Pipeline(steps=[\n",
    "    ('processor', feature_processor),\n",
    "    ('clf',DecisionTreeClassifier())\n",
    "])\n",
    "pipe_tree_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487db0f-6d15-4f7e-864e-297715d0ba27",
   "metadata": {},
   "source": [
    "We'll run a quick grid search to fine-tune the depth of the decision tree. \n",
    "First, we need to pick the right evaluation metric. \n",
    "This depends on the specific goals and problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390e8b3-1b57-4585-9153-3fce3087f07b",
   "metadata": {},
   "source": [
    "Instead of using accuracy, which isn’t a good metric for imbalanced data, Let’s say it’s important to both find high-income people and keep predictions accurate. So we’ll use F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd6b43-06f5-4a87-979a-6a7d685cef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1445a-2aa8-41c4-bcaa-f41e734d2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the number of neighbors \n",
    "param_grid = {\n",
    "    'clf__max_depth': range(3,11) \n",
    "}\n",
    "\n",
    "# Set up the grid search using balanced accuracy as the scoring metric\n",
    "grid_search = GridSearchCV(pipe_tree_clf, param_grid, scoring='f1', cv=5, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Run the grid search on the training data\n",
    "grid_search.fit(X_train, y_train.map({'<=50K':0,'>50K':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e741b0-2fdc-4f0b-84bd-a55f582bfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe_clf = grid_search.best_estimator_\n",
    "y_test_pred = best_pipe_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b701a37-ae2a-47bb-b4ae-ee8623364ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy (we know it could be misleading)\n",
    "accuracy_score(y_test.map({'<=50K':0,'>50K':1}),y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4323c8d-f12b-4d21-bc62-eb38beacf2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(best_pipe_clf,X_test,y_test.map({'<=50K':0,'>50K':1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1fa243-3cd8-49e6-87c2-52a8df2501f5",
   "metadata": {},
   "source": [
    "The model hardly predicts the minority class. This is reflected in the lower f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316f83c-f58f-44ed-b8f3-aae0fdd8db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202011b3-37f6-4e2e-9a4a-8406f9a7bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62757ed8-2c24-4e50-abda-57a0166e7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test.map({'<=50K':0,'>50K':1}), y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68ae4e-11f1-4baf-ba9d-5c6217bd2feb",
   "metadata": {},
   "source": [
    "The imbalance is causing the model to focus too much on the majority class. What can we do to compensate for this?\n",
    "As far as I know, there are three strategies:\n",
    "\n",
    "1. Some scikit-learn models have a `class_weight` parameter, which you can use to give more importance to the minority class and help the model focus on it.\n",
    "2. You can also handle imbalance by oversampling the minority class (adding more examples) or undersampling the majority class (removing examples). Another popular method is [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) (Synthetic Minority Over-sampling Technique), which creates synthetic samples of the minority class to balance the dataset.\n",
    "3.  You can also adjust the classification threshold.\n",
    "\n",
    "We'll focus on the third strategy: adjusting the classification threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c69e4-b4fe-4606-b5ed-ada5fa71e389",
   "metadata": {},
   "source": [
    "## 3. Adjusting the classification threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f79e2-a0fd-491f-bae5-1af2b7a1bf0c",
   "metadata": {},
   "source": [
    "We know we can manually change the classification threshold. We'll use this to see if we can improve the results for the minority class. But before that, we need to tune the hyperparameters of our model. Since we're going to change the classification threshold later, we need to do the grid search using a 'threshold-independent' evaluation metric. We've seen two examples: AUC (Area Under the Curve) and AP (Average Precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995fa9e-c28e-4520-84d1-43b2e31d07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the decision tree\n",
    "param_grid = {\n",
    "    'clf__max_depth': range(3, 11),  \n",
    "}\n",
    "\n",
    "# Set up the grid search using AP (Average Precision) as the scoring metric\n",
    "grid_search = GridSearchCV(pipe_tree_clf, param_grid, scoring='average_precision', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Run the grid search on the training data\n",
    "grid_search.fit(X_train, y_train.map({'<=50K':0,'>50K':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b01c0f-cb26-437b-88fa-eb5934db0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e4c85-7cd1-4cf8-beb1-6b30f88430ec",
   "metadata": {},
   "source": [
    "Now, for the second step, we want to maximize our chosen evaluation metric—F1 in this case—based on the classification threshold. Depending on your application, you might want to maximize other metrics, like recall, precision, or something else. But the idea remains the same: we'll adjust the classification threshold to get the best performance for the metric we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0af34-4f37-43e4-a38b-64b409bd6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 as a function of threshold\n",
    "\n",
    "proba = best_pipe_clf.predict_proba(X_test)[:,1]\n",
    "thresholds = np.linspace(0,1,200) # 200 evenly spaced points on [0,1]\n",
    "\n",
    "f1s = []\n",
    "for threshold in thresholds:\n",
    "    y_test_pred = np.zeros(len(y_test)) # vector of all zeros\n",
    "    y_test_pred[proba > threshold]=1\n",
    "    f1s.append(f1_score(y_test.map({'<=50K':0,'>50K':1}),\n",
    "                                                       y_test_pred\n",
    "                                                      )\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84df64-989d-4b96-814b-89356de6a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds,f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9951106-ec39-48af-bf05-ca2c4882c064",
   "metadata": {},
   "source": [
    "F1 is maximized at a very low threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ea038-3f58-4bc8-909c-37c694a7680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = thresholds[np.argmax(f1s)]\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b0a88-9ea7-44df-95a5-0363cf72bfdc",
   "metadata": {},
   "source": [
    "Now, let's use this threshold and test our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e4b91-398d-40a4-ac24-0f7de557c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.zeros(len(y_test)) # vector of all zeros\n",
    "y_test_pred[proba > threshold]=1\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.map({'<=50K':0,'>50K':1}),\n",
    "                                        y_test_pred\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e9b4b-a531-4de2-aace-0e5ae7fa095d",
   "metadata": {},
   "source": [
    "Now the model is finally predicting the minority class! Of course, we pay a price with a higher false positive rate, but that's a small trade-off if predicting the minority class is what matters most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780ef13-be15-48aa-8134-c5810f42cc40",
   "metadata": {},
   "source": [
    "The same, but using scikit learn built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60781e36-367b-4428-be4d-40acf1f69a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TunedThresholdClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2000b-7435-4155-949f-92a955abb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_pipe = TunedThresholdClassifierCV(estimator=best_pipe_clf, \n",
    "                                        scoring=\"f1\",\n",
    "                                       thresholds=300,\n",
    "                                        n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c8324-0686-41f8-b029-a7dcb2cd413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_pipe.fit(X_train, y_train.map({'<=50K':0,'>50K':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fba73-c813-4667-8278-17753d70077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_pipe.best_threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16039ab9-8e3d-4fad-999f-8244e265b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = tuned_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364526db-143d-4593-a199-6858051b366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test.map({'<=50K':0,'>50K':1}),\n",
    "                                        y_test_pred\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d73c9f-e1c5-455b-b5c6-e70855e601cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
