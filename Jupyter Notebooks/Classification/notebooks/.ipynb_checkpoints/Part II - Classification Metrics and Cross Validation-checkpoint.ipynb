{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Classification Models: Metrics and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve trained a classification model, possibly one of the models we’ve discussed, like logistic regression, k-nearest neighbors, decision trees, or another you’re familiar with. The model makes predictions—but how good are those predictions? This is the key question, and answering it can be challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a method to evaluate the model’s predictions.\n",
    "This allows us to compare different models—like k-NN, logistic regression, decision trees—and choose the best one. It also helps us fine-tune hyperparameters to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where model **evaluation metrics** come into play.\n",
    "Scikit-learn provides a variety of these metrics, and we’ll explore several of the most important ones in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents:\n",
    "\n",
    "- [Train-Test Split](#1.-Train-Test-Split)\n",
    "- [Evaluating a Classifier’s Performance](#2.-Evaluating-a-Classifier’s-Performance)\n",
    "- [Cross Validation](#3.-Cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve trained a model, but the key question is: how well will it generalize to new, unseen data? Of course, we don’t have access to this unseen data right now. So, what can we do?\n",
    "We need a method to estimate how well our model will perform on future data without actually having that data in hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s load a dataset known as the Pima Indians Diabetes dataset. This dataset contains medical data from Pima Indian women. The goal is to predict whether or not a patient has diabetes based on several medical factors, such as age, blood pressure, and body mass index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Pima indian diabetes dataset\n",
    "path = 'https://raw.githubusercontent.com/um-perez-alvaro/Data-Science-Practice/master/Data/pima.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pima Indians Diabetes dataset comes from a study conducted by the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
    "It focuses on the Pima Indian population, a group of Native Americans living in Arizona.\n",
    "This group was chosen because they have a high prevalence of Type 2 diabetes.\n",
    "\n",
    "The dataset contains medical information from 768 female patients of Pima Indian heritage, including factors like age, body mass index (BMI), blood pressure, and blood glucose concentration. The goal of the study was to identify factors that could predict the likelihood of diabetes onset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column     | Description |\n",
    "|------------|-------------|\n",
    "| **pregnant** | Number of pregnancies the patient has had |\n",
    "| **glucose**  | Plasma glucose concentration 2 hours after an oral glucose tolerance test |\n",
    "| **bp**       | Diastolic blood pressure (mm Hg) |\n",
    "| **skin**     | Triceps skin fold thickness (mm) |\n",
    "| **insulin**  | 2-hour serum insulin (mu U/ml) |\n",
    "| **bmi**      | Body mass index (weight in kg/(height in m)^2) |\n",
    "| **pedigree** | Diabetes pedigree function (a measure of family history and genetic risk) |\n",
    "| **age**      | Age of the patient (years) |\n",
    "| **label**    | whether the patient has diabetes: 1 for diabetic and 0 for non-diabetic |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represents a patient, and the label column indicates whether the patient has diabetes: 1 for diabetic and 0 for non-diabetic. Let’s now check how many patients in the dataset are classified as diabetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.label.value_counts() # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s build the feature matrix and the target vector. The feature matrix will contain all the input variables (e.g., glucose, blood pressure, BMI), while the target vector will hold the labels indicating whether each patient has diabetes (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature matrix X, target vector y\n",
    "X = df[feature_cols]\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate \"having unseen, new data\", we use a **train-test split**. \n",
    "We divide the dataset into two parts: the **training set**, used to train the model, and the **test set**, used to evaluate its performance on unseen data.\n",
    "\n",
    "Here’s how to do it with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `test_size=0.2`, 20% of the data is set aside for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use a k-NN model to train on the training set and then predict the labels (diabetes) for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the k-NN model with 10 neighbors \n",
    "knn_clf = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict labels for the test set\n",
    "y_test_pred = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `they` not found.\n"
     ]
    }
   ],
   "source": [
    "Now that we have the predictions, how good are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluating a Classifier’s Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess how well our model performed, we’ll use an **evaluation metric** to compare the actual labels (`y_test`) with the predicted labels (`y_test_pred`). \n",
    "Scikit-learn provides many evaluation metrics for this purpose. You can explore the full list on the [scikit-learn reference page](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
    "\n",
    "Let’s take a look at some of the most commonly used evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** is a common evaluation metric that measures the proportion of correct predictions made by the model. \n",
    "It’s calculated as the number of correct predictions divided by the total number of predictions. In other words, accuracy tells us what percentage of the predictions were correct.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like about 72% of the predictions are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix provides a more nuanced view of the model's predictions compared to simple accuracy.\n",
    "It shows how often the model correctly or incorrectly classifies each class.\n",
    "\n",
    "The matrix has four key components:\n",
    "\n",
    "- **True Positives (TP)**: The number of times the model correctly predicted the positive class (label 1).\n",
    "- **True Negatives (TN)**: The number of times the model correctly predicted the negative class (label 0).\n",
    "- **False Positives (FP)**: The number of times the model incorrectly predicted the positive class (also known as a \"Type I error\").\n",
    "- **False Negatives (FN)**: The number of times the model incorrectly predicted the negative class (also known as a \"Type II error\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24b954f7c10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(knn_clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows the model’s performance:\n",
    "\n",
    "- 83 True Negatives (TN): The model correctly predicted 83 non-diabetic patients.\n",
    "- 13 False Positives (FP): The model incorrectly predicted 13 non-diabetic patients as diabetic.\n",
    "- 29 False Negatives (FN): The model incorrectly predicted 29 diabetic patients as non-diabetic.\n",
    "- 29 True Positives (TP): The model correctly predicted 29 diabetic patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 13],\n",
       "       [29, 29]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the confusion matrix with just the numerical values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Metrics computed from the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics like precision, recall, and F1-score are computed directly from the confusion matrix to provide deeper insights into model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the confusion matrix and extract its components\n",
    "confusion = confusion_matrix(y_test, y_test_pred)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** measures how often the model correctly predicts positive cases (label \n",
    "1) when the actual value is positive. It answers the question: \"Out of all the actual positives, how many did the model correctly identify?\"\n",
    "\n",
    "The formula for recall is:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** measures how often the model's positive predictions are correct. It answers the question: \"Out of all the predicted positives, how many were actually positive?\"\n",
    "\n",
    "The formula for precision is:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904761904761905"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904761904761905"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall vs Precision**: Which metric should you focus on? \n",
    "The choice of metric depends on the specific goal of your model.\n",
    "Here are some examples:\n",
    "- Spam filter (positive class = \"spam\"): Focus on precision because false negatives (spam in the inbox) are less harmful than false positives (legitimate emails marked as spam).\n",
    "- Fraud detection (positive class = \"fraud\"): Focus on recall (sensitivity) because missing a fraudulent transaction (false negative) is worse than flagging a legitimate one (false positive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score**  \n",
    "The F1 score is the harmonic mean of precision and recall. \n",
    "It provides a balance between the two metrics and is particularly useful when you need a single measure that captures both false positives and false negatives.\n",
    "The F1 score is best used when the class distribution is imbalanced, and you need to weigh both precision and recall equally.\n",
    "\n",
    "The formula for the F1 score is:\n",
    "\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Imbalanced datasets (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " An **imbalanced dataset** is one where the classes are not represented equally. For example, in a dataset where 90% of the instances belong to one class and only 10% to the other, the model might become biased towards predicting the majority class. This can make accuracy misleading, as it doesn’t capture the model’s ability to correctly predict the minority class.\n",
    "\n",
    "When dealing with imbalanced datasets, accuracy alone may not be enough to evaluate your model’s performance.\n",
    "Here is an evaluation metric that you can use to get a better understanding of how well your model is performing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced Accuracy**  \n",
    "Balanced accuracy is the average of recall calculated separately for each class, making it a useful metric when dealing with imbalanced datasets. It ensures that the performance of both classes (positive and negative) is equally considered, avoiding bias toward the majority class.\n",
    "\n",
    "The formula for balanced accuracy is:\n",
    "\n",
    "$$\n",
    "\\text{Balanced Accuracy} = \\frac{\\text{Recall for Class 0} + \\text{Recall for Class 1}}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6822916666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a more reliable way to evaluate your model compared to a simple train-test split. Why? Because with the train-test split, you're only testing the model on one part of the data. If that split isn’t representative, your results might not reflect how well the model actually performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k-fold cross-validation, we split the data into $k$ equal parts (folds).\n",
    "The model is trained on $k-1$ folds and tested on the remaining one. \n",
    "This process is repeated $k$ times, with each fold getting a chance to be the test set. \n",
    "At the end, you average the results, giving you a more reliable estimate of how well the model will perform on unseen data.\n",
    "\n",
    "<td> <img src=\"cross_validation.png\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s how to do it in scikit-learn.\n",
    "In this example, we use 5-fold cross-validation to get five different accuracy scores, and then we take the average to get a better sense of how the model performs overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74675325, 0.72077922, 0.75974026, 0.78431373, 0.7124183 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(knn_clf, X, y, cv=5)\n",
    "\n",
    "# Print the accuracy for each fold \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448009506833035"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the average score\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
